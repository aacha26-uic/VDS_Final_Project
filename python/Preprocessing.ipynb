{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "90b3adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7d9c2488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "utterance_df = pd.read_excel(\"../data/utterance_data.xlsx\")\n",
    "linguistic_df = pd.read_excel(\"../data/linguistic_outcomes.xlsx\")\n",
    "demographics_df = pd.read_excel(\"../data/demographic(1).xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "94c87779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'file', 'utterance', 'DX1', 'label', 'ncc', 'MOCATOTS',\n",
      "       'MOCA_impairment', 'age', 'race', 'gender', 'educ'],\n",
      "      dtype='object')\n",
      "Index(['file', '# utterances (overall)', '# utterances (interviewer)',\n",
      "       '# utterances (participant)', '# tokens (overall)',\n",
      "       '# tokens (interviewer)', '# tokens (participant)',\n",
      "       '# unique tokens (overall)', '# unique tokens (interviewer)',\n",
      "       '# unique tokens (participant)',\n",
      "       ...\n",
      "       'MATTR (participant)', 'Maas (overall)', 'Maas (interviewer)',\n",
      "       'Maas (participant)', 'MTLD (overall)', 'MTLD (interviewer)',\n",
      "       'MTLD (participant)', 'HD-D (overall)', 'HD-D (interviewer)',\n",
      "       'HD-D (participant)'],\n",
      "      dtype='object', length=142)\n",
      "Index(['REGTRYID', 'ADRC_COGNITIVE_DATA', 'ADRCVIS', 'Assessment.Date',\n",
      "       'PTINIT', 'RID', 'VISCODE', 'FORMVER', 'SITEID', 'ENTRY',\n",
      "       ...\n",
      "       'LUMI_TAU_POS', 'tTau_AB42Positivity', 'pTau_AB42Ratio',\n",
      "       'AB42_AB40Positivity', 'VAR00001', 'VAR00002', 'VAR00003', 'VAR00004',\n",
      "       'VAR00005', 'VAR00006'],\n",
      "      dtype='object', length=169)\n"
     ]
    }
   ],
   "source": [
    "# print(utterance_df.head())\n",
    "# print(linguistic_df.head())\n",
    "# print(demographics_df.head())\n",
    "\n",
    "print(utterance_df.columns)\n",
    "print(linguistic_df.columns)\n",
    "print(demographics_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b77b5b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['file', 'utterance', 'DX1', 'label', 'ncc', 'MOCATOTS',\n",
      "       'MOCA_impairment', 'age', 'race', 'gender', 'educ'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# removing extra column\n",
    "utterance_df = utterance_df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "print(utterance_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "346e1bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['file', 'utterance', 'DX1', 'label', 'ncc', 'MOCATOTS',\n",
      "       'MOCA_impairment', 'age', 'race', 'gender', 'educ'],\n",
      "      dtype='object')\n",
      "Index(['file', 'utterances(overall)', 'utterances(interviewer)',\n",
      "       'utterances(participant)', 'tokens(overall)', 'tokens(interviewer)',\n",
      "       'tokens(participant)', 'uniquetokens(overall)',\n",
      "       'uniquetokens(interviewer)', 'uniquetokens(participant)',\n",
      "       ...\n",
      "       'MATTR(participant)', 'Maas(overall)', 'Maas(interviewer)',\n",
      "       'Maas(participant)', 'MTLD(overall)', 'MTLD(interviewer)',\n",
      "       'MTLD(participant)', 'HD-D(overall)', 'HD-D(interviewer)',\n",
      "       'HD-D(participant)'],\n",
      "      dtype='object', length=142)\n"
     ]
    }
   ],
   "source": [
    "# formatting the column names\n",
    "utterance_df.columns = utterance_df.columns.str.strip().str.replace(' ', '')\n",
    "linguistic_df.columns = linguistic_df.columns.str.strip().str.replace(' ', '').str.replace('#', '')\n",
    "\n",
    "print(utterance_df.columns)\n",
    "print(linguistic_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "148b5aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of dataset with the necessary columns\n",
    "utterance_df_subset = utterance_df[['file', 'utterance', 'DX1', 'MOCATOTS', 'MOCA_impairment', 'age', 'gender', 'educ']]\n",
    "linguistic_df_subset = linguistic_df[['file', 'tokens(participant)', 'uniquetokens(participant)', 'AUX(participant)', 'CCONJ(participant)', 'NUM(participant)', 'PROPN(participant)', 'VERB(participant)', 'DATE(participant)', 'TTR(participant)', 'MATTR(participant)']]\n",
    "demographic_df_subset = demographics_df[['REGTRYID', 'AB40_LUMI', 'AB42_LUMI', 'P_TAU_LUMI', 'T_TAU_LUMI', 'AB42_AB40Ratio', 'tTau_AB42Ratio', 'pTau_AB42Ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "69bfbf61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file               0\n",
       "utterance          0\n",
       "DX1                0\n",
       "MOCATOTS           0\n",
       "MOCA_impairment    0\n",
       "age                8\n",
       "gender             8\n",
       "educ               8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values for in utterance data\n",
    "utterance_df_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0f12d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: mean = 76.08, median = 75.00\n",
      "gender: mean = 0.55, median = 1.00\n",
      "educ: mean = 17.36, median = 18.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age       0.749923\n",
       "gender   -0.222190\n",
       "educ     -0.250832\n",
       "dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fill in missing values checking mean, median or mode is better in utterance data\n",
    "numeric_cols = ['age', 'gender', 'educ']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    mean_val = utterance_df_subset[col].mean()\n",
    "    median_val = utterance_df_subset[col].median()\n",
    "    print(f\"{col}: mean = {mean_val:.2f}, median = {median_val:.2f}\")\n",
    "\n",
    "utterance_df_subset[numeric_cols].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6711690b",
   "metadata": {},
   "source": [
    "Age is positively skewed, and the mean and median are almost the same, but since the median is slightly lower, the median will be used to fill missing values.\n",
    "Gender is coded 0/1, so using the mode would be better for filling missing values.\n",
    "Education (educ) is slightly negatively skewed, with a higher median; therefore, the median will be used to fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "77d43c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/b8zy5xq90hxdqyzpsx60rng80000gn/T/ipykernel_44045/3333559885.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  utterance_df_subset[cols] = utterance_df_subset[cols].fillna(medians)\n",
      "/var/folders/4h/b8zy5xq90hxdqyzpsx60rng80000gn/T/ipykernel_44045/3333559885.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  utterance_df_subset['gender'] = utterance_df_subset['gender'].fillna(mode_val)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "file               0\n",
       "utterance          0\n",
       "DX1                0\n",
       "MOCATOTS           0\n",
       "MOCA_impairment    0\n",
       "age                0\n",
       "gender             0\n",
       "educ               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filling the missing values in utterance data\n",
    "cols = ['age', 'educ']\n",
    "medians = utterance_df_subset[cols].median()\n",
    "utterance_df_subset[cols] = utterance_df_subset[cols].fillna(medians)\n",
    "\n",
    "mode_val = utterance_df_subset['gender'].mode()[0]\n",
    "utterance_df_subset['gender'] = utterance_df_subset['gender'].fillna(mode_val)\n",
    "\n",
    "utterance_df_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "04fe4c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file                         0\n",
       "tokens(participant)          4\n",
       "uniquetokens(participant)    4\n",
       "AUX(participant)             4\n",
       "CCONJ(participant)           4\n",
       "NUM(participant)             4\n",
       "PROPN(participant)           4\n",
       "VERB(participant)            4\n",
       "DATE(participant)            4\n",
       "TTR(participant)             4\n",
       "MATTR(participant)           4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in linguistic data\n",
    "linguistic_df_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "285b130b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens(participant): mean = 659.30, median = 663.00\n",
      "uniquetokens(participant): mean = 236.87, median = 248.50\n",
      "AUX(participant): mean = 47.73, median = 48.50\n",
      "CCONJ(participant): mean = 37.70, median = 35.00\n",
      "NUM(participant): mean = 10.38, median = 10.00\n",
      "PROPN(participant): mean = 21.76, median = 20.00\n",
      "VERB(participant): mean = 75.90, median = 77.50\n",
      "DATE(participant): mean = 5.19, median = 4.00\n",
      "TTR(participant): mean = 0.42, median = 0.37\n",
      "MATTR(participant): mean = 0.99, median = 0.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokens(participant)         -0.007291\n",
       "uniquetokens(participant)   -0.415031\n",
       "AUX(participant)             0.247956\n",
       "CCONJ(participant)           0.366389\n",
       "NUM(participant)             0.321662\n",
       "PROPN(participant)           1.123676\n",
       "VERB(participant)            0.169596\n",
       "DATE(participant)            1.082661\n",
       "TTR(participant)             2.252689\n",
       "MATTR(participant)          -2.007696\n",
       "dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fill in missing values checking mean, median or mode is better in linguistic data\n",
    "numeric_cols = ['tokens(participant)', 'uniquetokens(participant)', 'AUX(participant)', 'CCONJ(participant)', 'NUM(participant)', 'PROPN(participant)', 'VERB(participant)', 'DATE(participant)', 'TTR(participant)', 'MATTR(participant)']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    mean_val = linguistic_df_subset[col].mean()\n",
    "    median_val = linguistic_df_subset[col].median()\n",
    "    print(f\"{col}: mean = {mean_val:.2f}, median = {median_val:.2f}\")\n",
    "\n",
    "linguistic_df_subset[numeric_cols].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272aadd4",
   "metadata": {},
   "source": [
    "Tokens are symmetrical and almost 0, so the mean will be used to fill in missing values.\\\n",
    "Unique Tokens is slightly skewed, so the median is a better option.\\\n",
    "AUX is distributed symmetrically, so the mean will be used to fill in missing values.\\\n",
    "CCONJ is slightly skewed; the median will be used to fill in missing values.\\\n",
    "The NUM is skewed somewhat; therefore, the median will be used to fill in the missing values.\\\n",
    "PROPN is quite positively skewed, so the median would be a better option.\\\n",
    "VERB is almost symmetrical, and the mean will be used to fill in missing values.\\\n",
    "DATE is positively skewed, and the median will be used to fill in missing values.\\\n",
    "TTR is highly skewed, and the median would be a better option.\\\n",
    "MATTR is highly negatively skewed; therefore, the median will be used to fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cae5370c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/b8zy5xq90hxdqyzpsx60rng80000gn/T/ipykernel_44045/3212703898.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(mean_val)\n",
      "/var/folders/4h/b8zy5xq90hxdqyzpsx60rng80000gn/T/ipykernel_44045/3212703898.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(median_val)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "file                         0\n",
       "tokens(participant)          0\n",
       "uniquetokens(participant)    0\n",
       "AUX(participant)             0\n",
       "CCONJ(participant)           0\n",
       "NUM(participant)             0\n",
       "PROPN(participant)           0\n",
       "VERB(participant)            0\n",
       "DATE(participant)            0\n",
       "TTR(participant)             0\n",
       "MATTR(participant)           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filling the missing values in linguistic data\n",
    "df = linguistic_df_subset\n",
    "mean_cols   = ['tokens(participant)', 'AUX(participant)', 'VERB(participant)']\n",
    "median_cols = ['uniquetokens(participant)',\n",
    "               'CCONJ(participant)', 'NUM(participant)',\n",
    "               'PROPN(participant)', 'DATE(participant)',\n",
    "               'TTR(participant)', 'MATTR(participant)']\n",
    "\n",
    "# fill in mean columns\n",
    "for col in mean_cols:\n",
    "    mean_val = df[col].mean()\n",
    "    df[col] = df[col].fillna(mean_val)\n",
    "\n",
    "# fill in median columns\n",
    "for col in median_cols:\n",
    "    median_val = df[col].median()\n",
    "    df[col] = df[col].fillna(median_val)\n",
    "\n",
    "linguistic_df_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "af8984ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REGTRYID           0\n",
       "AB40_LUMI         11\n",
       "AB42_LUMI         11\n",
       "P_TAU_LUMI        11\n",
       "T_TAU_LUMI        11\n",
       "AB42_AB40Ratio    11\n",
       "tTau_AB42Ratio    11\n",
       "pTau_AB42Ratio    11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_df_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3567b531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB40_LUMI: mean = 11410.40, median = 11354.50\n",
      "AB42_LUMI: mean = 875.04, median = 788.00\n",
      "P_TAU_LUMI: mean = 46.33, median = 39.25\n",
      "T_TAU_LUMI: mean = 348.26, median = 316.50\n",
      "AB42_AB40Ratio: mean = 0.08, median = 0.09\n",
      "tTau_AB42Ratio: mean = 0.60, median = 0.33\n",
      "pTau_AB42Ratio: mean = 0.08, median = 0.04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AB40_LUMI         0.331881\n",
       "AB42_LUMI         0.737590\n",
       "P_TAU_LUMI        1.915302\n",
       "T_TAU_LUMI        1.451436\n",
       "AB42_AB40Ratio   -0.499330\n",
       "tTau_AB42Ratio    7.975608\n",
       "pTau_AB42Ratio    7.627163\n",
       "dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fill in missing values checking mean, median or mode is better in utterance data\n",
    "numeric_cols = ['AB40_LUMI','AB42_LUMI','P_TAU_LUMI','T_TAU_LUMI','AB42_AB40Ratio','tTau_AB42Ratio','pTau_AB42Ratio']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    mean_val = demographic_df_subset[col].mean()\n",
    "    median_val = demographic_df_subset[col].median()\n",
    "    print(f\"{col}: mean = {mean_val:.2f}, median = {median_val:.2f}\")\n",
    "\n",
    "demographic_df_subset[numeric_cols].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6588887",
   "metadata": {},
   "source": [
    "For AB40_LUMI, the mean and median are close, and the distribution is slightly skewed; therefore, the mean would be a better option.\\\n",
    "For AB42_LUMI, the mean is larger, and it is skewed; therefore, the median would be a better option.\\\n",
    "For P_TAU_LUMI, it is highly skewed, so the median would be a better option.\n",
    "T_TAU_LUMI is highly skewed, so the median would be a better option.\\\n",
    "The AB42_AB40 ratio is negatively skewed, so the median would be a better option.\\\n",
    "Tau_AB42Ratio is very highly positively skewed; the median would be a better option.\\\n",
    "pTau_AB42Ratio is very highly positively skewed; the median would be a better option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "082c87b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/b8zy5xq90hxdqyzpsx60rng80000gn/T/ipykernel_44045/308922001.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(mean_val)\n",
      "/var/folders/4h/b8zy5xq90hxdqyzpsx60rng80000gn/T/ipykernel_44045/308922001.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(median_val)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "REGTRYID          0\n",
       "AB40_LUMI         0\n",
       "AB42_LUMI         0\n",
       "P_TAU_LUMI        0\n",
       "T_TAU_LUMI        0\n",
       "AB42_AB40Ratio    0\n",
       "tTau_AB42Ratio    0\n",
       "pTau_AB42Ratio    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filling the missing values in linguistic data\n",
    "df = demographic_df_subset\n",
    "\n",
    "mean_cols = ['AB40_LUMI']\n",
    "median_cols = [\n",
    "    'AB42_LUMI', 'P_TAU_LUMI', 'T_TAU_LUMI',\n",
    "    'AB42_AB40Ratio', 'tTau_AB42Ratio', 'pTau_AB42Ratio'\n",
    "]\n",
    "\n",
    "for col in mean_cols:\n",
    "    mean_val = df[col].mean()\n",
    "    df[col] = df[col].fillna(mean_val)\n",
    "\n",
    "for col in median_cols:\n",
    "    median_val = df[col].median()\n",
    "    df[col] = df[col].fillna(median_val)\n",
    "    \n",
    "demographic_df_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6bdf8194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['file', 'utterance', 'DX1', 'MOCATOTS', 'MOCA_impairment', 'age',\n",
      "       'gender', 'educ', 'tokens(participant)', 'uniquetokens(participant)',\n",
      "       'AUX(participant)', 'CCONJ(participant)', 'NUM(participant)',\n",
      "       'PROPN(participant)', 'VERB(participant)', 'DATE(participant)',\n",
      "       'TTR(participant)', 'MATTR(participant)', 'REGTRYID', 'AB40_LUMI',\n",
      "       'AB42_LUMI', 'P_TAU_LUMI', 'T_TAU_LUMI', 'AB42_AB40Ratio',\n",
      "       'tTau_AB42Ratio', 'pTau_AB42Ratio'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# merging linguistics and utterance dataset for analyzing later\n",
    "merged_df = pd.merge(utterance_df_subset, linguistic_df_subset, on='file', how='inner')\n",
    "\n",
    "# a new column that matches the REGTRYID in demographics\n",
    "merged_df['REGTRYID'] = merged_df['file'].str.split('_').str[0].astype(int)\n",
    "\n",
    "# final merge with demographics\n",
    "final_merged_df = pd.merge(\n",
    "    merged_df,\n",
    "    demographic_df_subset,\n",
    "    on='REGTRYID',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(final_merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d07e1ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOCATOTS</th>\n",
       "      <th>MOCA_impairment</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>educ</th>\n",
       "      <th>tokens(participant)</th>\n",
       "      <th>uniquetokens(participant)</th>\n",
       "      <th>AUX(participant)</th>\n",
       "      <th>CCONJ(participant)</th>\n",
       "      <th>NUM(participant)</th>\n",
       "      <th>...</th>\n",
       "      <th>TTR(participant)</th>\n",
       "      <th>MATTR(participant)</th>\n",
       "      <th>REGTRYID</th>\n",
       "      <th>AB40_LUMI</th>\n",
       "      <th>AB42_LUMI</th>\n",
       "      <th>P_TAU_LUMI</th>\n",
       "      <th>T_TAU_LUMI</th>\n",
       "      <th>AB42_AB40Ratio</th>\n",
       "      <th>tTau_AB42Ratio</th>\n",
       "      <th>pTau_AB42Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.255556</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>75.766667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>659.302326</td>\n",
       "      <td>237.388889</td>\n",
       "      <td>47.732558</td>\n",
       "      <td>37.577778</td>\n",
       "      <td>10.366667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414374</td>\n",
       "      <td>0.989129</td>\n",
       "      <td>3796.344444</td>\n",
       "      <td>11410.400000</td>\n",
       "      <td>865.366667</td>\n",
       "      <td>45.538889</td>\n",
       "      <td>344.733333</td>\n",
       "      <td>0.078479</td>\n",
       "      <td>0.566915</td>\n",
       "      <td>0.077772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.497464</td>\n",
       "      <td>0.410383</td>\n",
       "      <td>5.205982</td>\n",
       "      <td>0.492642</td>\n",
       "      <td>2.015669</td>\n",
       "      <td>330.553335</td>\n",
       "      <td>94.221493</td>\n",
       "      <td>26.843041</td>\n",
       "      <td>21.338880</td>\n",
       "      <td>6.698063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137472</td>\n",
       "      <td>0.007830</td>\n",
       "      <td>843.527041</td>\n",
       "      <td>3240.589229</td>\n",
       "      <td>363.758083</td>\n",
       "      <td>24.268190</td>\n",
       "      <td>170.165059</td>\n",
       "      <td>0.023422</td>\n",
       "      <td>1.180730</td>\n",
       "      <td>0.165960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278298</td>\n",
       "      <td>0.955502</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>4599.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>0.149340</td>\n",
       "      <td>0.022525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>440.750000</td>\n",
       "      <td>185.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338058</td>\n",
       "      <td>0.986332</td>\n",
       "      <td>3566.000000</td>\n",
       "      <td>9171.500000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>30.125000</td>\n",
       "      <td>226.750000</td>\n",
       "      <td>0.058727</td>\n",
       "      <td>0.250080</td>\n",
       "      <td>0.033274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>660.151163</td>\n",
       "      <td>248.500000</td>\n",
       "      <td>47.732558</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371693</td>\n",
       "      <td>0.989751</td>\n",
       "      <td>3684.000000</td>\n",
       "      <td>11410.400000</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>39.250000</td>\n",
       "      <td>316.500000</td>\n",
       "      <td>0.086684</td>\n",
       "      <td>0.327180</td>\n",
       "      <td>0.038540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>863.750000</td>\n",
       "      <td>300.250000</td>\n",
       "      <td>65.750000</td>\n",
       "      <td>52.750000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430856</td>\n",
       "      <td>0.994091</td>\n",
       "      <td>3764.500000</td>\n",
       "      <td>13445.000000</td>\n",
       "      <td>1051.250000</td>\n",
       "      <td>50.100000</td>\n",
       "      <td>406.250000</td>\n",
       "      <td>0.093296</td>\n",
       "      <td>0.505736</td>\n",
       "      <td>0.062109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1387.000000</td>\n",
       "      <td>441.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8264.000000</td>\n",
       "      <td>22797.000000</td>\n",
       "      <td>2113.000000</td>\n",
       "      <td>163.400000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>0.123842</td>\n",
       "      <td>11.217391</td>\n",
       "      <td>1.550000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MOCATOTS  MOCA_impairment        age     gender       educ  \\\n",
       "count  90.000000        90.000000  90.000000  90.000000  90.000000   \n",
       "mean   19.255556         0.211111  75.766667   0.600000  17.400000   \n",
       "std     2.497464         0.410383   5.205982   0.492642   2.015669   \n",
       "min     8.000000         0.000000  67.000000   0.000000  10.000000   \n",
       "25%    18.000000         0.000000  72.250000   0.000000  16.000000   \n",
       "50%    20.000000         0.000000  75.000000   1.000000  18.000000   \n",
       "75%    21.000000         0.000000  79.000000   1.000000  18.000000   \n",
       "max    22.000000         1.000000  90.000000   1.000000  24.000000   \n",
       "\n",
       "       tokens(participant)  uniquetokens(participant)  AUX(participant)  \\\n",
       "count            90.000000                  90.000000         90.000000   \n",
       "mean            659.302326                 237.388889         47.732558   \n",
       "std             330.553335                  94.221493         26.843041   \n",
       "min               7.000000                   6.000000          0.000000   \n",
       "25%             440.750000                 185.750000         25.000000   \n",
       "50%             660.151163                 248.500000         47.732558   \n",
       "75%             863.750000                 300.250000         65.750000   \n",
       "max            1387.000000                 441.000000        115.000000   \n",
       "\n",
       "       CCONJ(participant)  NUM(participant)  ...  TTR(participant)  \\\n",
       "count           90.000000         90.000000  ...         90.000000   \n",
       "mean            37.577778         10.366667  ...          0.414374   \n",
       "std             21.338880          6.698063  ...          0.137472   \n",
       "min              0.000000          0.000000  ...          0.278298   \n",
       "25%             24.000000          5.000000  ...          0.338058   \n",
       "50%             35.000000         10.000000  ...          0.371693   \n",
       "75%             52.750000         14.750000  ...          0.430856   \n",
       "max            106.000000         26.000000  ...          0.941176   \n",
       "\n",
       "       MATTR(participant)     REGTRYID     AB40_LUMI    AB42_LUMI  P_TAU_LUMI  \\\n",
       "count           90.000000    90.000000     90.000000    90.000000   90.000000   \n",
       "mean             0.989129  3796.344444  11410.400000   865.366667   45.538889   \n",
       "std              0.007830   843.527041   3240.589229   363.758083   24.268190   \n",
       "min              0.955502  2764.000000   4599.000000    46.000000   14.300000   \n",
       "25%              0.986332  3566.000000   9171.500000   608.000000   30.125000   \n",
       "50%              0.989751  3684.000000  11410.400000   788.000000   39.250000   \n",
       "75%              0.994091  3764.500000  13445.000000  1051.250000   50.100000   \n",
       "max              1.000000  8264.000000  22797.000000  2113.000000  163.400000   \n",
       "\n",
       "        T_TAU_LUMI  AB42_AB40Ratio  tTau_AB42Ratio  pTau_AB42Ratio  \n",
       "count    90.000000       90.000000       90.000000       90.000000  \n",
       "mean    344.733333        0.078479        0.566915        0.077772  \n",
       "std     170.165059        0.023422        1.180730        0.165960  \n",
       "min      99.000000        0.005765        0.149340        0.022525  \n",
       "25%     226.750000        0.058727        0.250080        0.033274  \n",
       "50%     316.500000        0.086684        0.327180        0.038540  \n",
       "75%     406.250000        0.093296        0.505736        0.062109  \n",
       "max    1012.000000        0.123842       11.217391        1.550000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b292f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing final merged df\n",
    "final_merged_df.to_csv(\"data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
